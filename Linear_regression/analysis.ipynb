{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Questions to the data\n",
    "1. Does the number of hauses in all houses groups remain stable or there were a construction side finished in the given time frame?\n",
    "2. What was the weather in the region?\n",
    "3. What was the price for gas/oil/elictricity?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "from data.starting_kit.utils import create_submission\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/public_data/train.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m final_index \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpseudo_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1254\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1252\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1253\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1254\u001B[0m     index, columns, col_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1255\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1256\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 225\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    227\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:883\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1026\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1072\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1187\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-cup-makcfd/venv_aicup2/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1240\u001B[0m, in \u001B[0;36mis_float_dtype\u001B[0;34m(arr_or_dtype)\u001B[0m\n\u001B[1;32m   1199\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;124;03m    Check whether the provided array or dtype is of a numeric dtype.\u001B[39;00m\n\u001B[1;32m   1201\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1233\u001B[0m \u001B[38;5;124;03m    False\u001B[39;00m\n\u001B[1;32m   1234\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _is_dtype_type(\n\u001B[1;32m   1236\u001B[0m         arr_or_dtype, classes_and_not_datetimelike(np\u001B[38;5;241m.\u001B[39mnumber, np\u001B[38;5;241m.\u001B[39mbool_)\n\u001B[1;32m   1237\u001B[0m     )\n\u001B[0;32m-> 1240\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_float_dtype\u001B[39m(arr_or_dtype) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m   1241\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;124;03m    Check whether the provided array or dtype is of a float dtype.\u001B[39;00m\n\u001B[1;32m   1243\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;124;03m    True\u001B[39;00m\n\u001B[1;32m   1270\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _is_dtype_type(arr_or_dtype, classes(np\u001B[38;5;241m.\u001B[39mfloating))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/public_data/train.csv')\n",
    "final_index = data['pseudo_id']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop index for feature preparation\n",
    "data_ = data.drop(columns='pseudo_id')\n",
    "# convert dates to pandas datetime\n",
    "data_.columns = [datetime.strptime(c, \"%Y-%m-%d %H:%M:%S\") for c in data_.columns]\n",
    "data_.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GROUP BY DAY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aggregate energy use values per day\n",
    "data_ = data_.T.groupby(data_.T.index.date).sum()\n",
    "data_.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# features[\"hour\"] = data.index.hour\n",
    "data_.columns = [c+1 for c in range(len(data_.columns))]\n",
    "data_.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check wether datetime in ascending order , it is important for time series\n",
    "print(data_.index.is_monotonic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set dates for development phase\n",
    "new_date_range = pd.date_range(start=\"2017-01-01\", end=\"2019-03-31\", freq=\"D\")\n",
    "# Add test dates in the data frame\n",
    "data_ = data_.reindex(new_date_range)\n",
    "# using dummy values in test set , fill_value = 100\n",
    "# df_ = df_.T\n",
    "\n",
    "#data_.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# saving indexes for next steps\n",
    "idx_test_date = data_.index[data_[1].isna()]\n",
    "idx_test_date"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_ = data_.fillna(method=\"backfill\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':160})\n",
    "#data_[1].plot()\n",
    "#plt.title('Energy use forecasts for houshold group' + \" 1\")\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_\\\n",
    "    .isna()\\\n",
    "    .sum()\\\n",
    "    .to_frame()\\\n",
    "    .assign(perc = lambda row: 100 * row[0] / data_.shape[0])\\\n",
    "    .rename(columns={0: 'Number of missed data  points', 'perc': '% of missed data points'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adding features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = data_.copy(deep=True)\n",
    "#df.drop(columns=['ord_mean_week','mean','std'],inplace=True)\n",
    "df[\"weekday\"] = data_.index.weekday\n",
    "df[\"dayofyear\"] = data_.index.dayofyear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"is_weekend\"] = data_.index.weekday.isin([5, 6]).astype(np.int32)\n",
    "#df[\"weekofyear\"] = data_.index.isocalendar\n",
    "df[\"month\"] = data_.index.month\n",
    "df[\"season\"] = (data_.index.month % 12 + 3) // 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_features(houshold_id,df=df) -> pd.DataFrame:\n",
    "    df_new = df[[houshold_id, \"weekday\", \"dayofyear\", \"is_weekend\", \"season\", \"month\"]]\n",
    "    df_new['std'] = df_new[houshold_id].rolling(7).std().fillna(method=\"backfill\")\n",
    "    df_new['mean'] = df_new[houshold_id].rolling(7).mean().fillna(method=\"backfill\")\n",
    "    df_new['lag_1'] = df[houshold_id].shift(1).fillna(method=\"backfill\")\n",
    "    df_new['lag_2'] = df[houshold_id].shift(2).fillna(method=\"backfill\")\n",
    "    df_new['lag_3'] = df_new[houshold_id].shift(3).fillna(method=\"backfill\")\n",
    "    df_new['lag_4'] = df_new[houshold_id].shift(4).fillna(method=\"backfill\")\n",
    "    df_new['lag_5'] = df_new[houshold_id].shift(5).fillna(method=\"backfill\")\n",
    "    df_new['lag_6'] = df_new[houshold_id].shift(6).fillna(method=\"backfill\")\n",
    "    df_new['lag_7'] = df_new[houshold_id].shift(7).fillna(method=\"backfill\")\n",
    "    return df_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_weeks(idx)-> List[List[pd._libs.tslibs.timestamps.Timestamp]]:\n",
    "    idx = list(idx)\n",
    "    count = 0\n",
    "    weeks_to_predict = []\n",
    "    week = []\n",
    "    for i in range(len(idx)):\n",
    "        if count > 6:\n",
    "            weeks_to_predict.append(week)\n",
    "            week = []\n",
    "            count = 0\n",
    "        week.append(idx[i])\n",
    "        count += 1\n",
    "    return weeks_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weeks_test_date = get_weeks(idx_test_date)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_split_accumlated(result, weeks, n, houshold) -> Tuple[Any, Any]:\n",
    "    print(weeks[n])\n",
    "    result_splitted = result[result.index < weeks[n][0]]\n",
    "    result_splitted_features = result_splitted.drop([houshold], axis=1)\n",
    "    result_splitted_target = result_splitted[houshold]\n",
    "    print(\"target: \", result_splitted_target)\n",
    "    result_splitted_to_predict = result[(result.index >= weeks[n][0]) & (result.index <= weeks[n][6])]\n",
    "    result_splitted_to_predict_features = result_splitted_to_predict.drop([houshold], axis=1)\n",
    "    result_splitted_to_predict_target = result_splitted_to_predict[houshold]\n",
    "    result_splitted_to_predict_target = result_splitted_to_predict_target.to_frame()\n",
    "\n",
    "    return result_splitted_features, result_splitted_target, result_splitted_to_predict_features, result_splitted_to_predict_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    " \n",
    "for houshold in data_.columns:\n",
    "    houshold_predictions = []\n",
    "    print(\"***** Houshold \" + str(houshold) + \" dataset created ****** \")\n",
    "    for week in range(len(weeks_test_date)):\n",
    "        #print(\"week \"+  str(week) + \" splitting started\")\n",
    "        result = create_features(houshold)\n",
    "        features, target, features_predict, target_predict = data_split_accumlated(result, weeks_test_date, week, houshold)\n",
    "        model_linear = LinearRegression()\n",
    "        model_linear.fit(features, target)\n",
    "        print(\"trained on \" + str(week))\n",
    "        prediction = model_linear.predict(features_predict)\n",
    "        houshold_predictions.append(prediction)\n",
    "        week_timestamps = weeks_test_date[week]\n",
    "        target_predict['predict'] = prediction\n",
    "        df.loc[week_timestamps[0]:week_timestamps[6],houshold] = target_predict['predict']\n",
    "        print(\"=============================================\")\n",
    "        print(prediction)\n",
    "        #print(df.loc[week_timestamps[0]:week_timestamps[6],houshold])\n",
    "        print(\"=============================================\")\n",
    "    all_predictions.append(houshold_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weeks_columns = [week for weeks in weeks_test_date for week in weeks]\n",
    "weeks_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flatten(hous):\n",
    "    return [week for weeks in hous for week in weeks]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flatened_predictions = []\n",
    "for hous in all_predictions:\n",
    "    flatened_predictions.append(flatten(hous))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_from_list = pd.DataFrame([i for i in flatened_predictions], columns= [weeks_columns],index = final_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_from_list.reset_index(inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_from_list.to_csv(\"./sample_submission_daily_max.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_from_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "daily = pd.read_csv(\"./sample_submission_daily_max.csv\")\n",
    "hourly = pd.read_csv(\"./sample_submission_hourly_max.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote submission-2022-06-25_11-10-25.780745.zip\n"
     ]
    }
   ],
   "source": [
    "create_submission(daily,hourly)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}